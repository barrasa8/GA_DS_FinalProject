{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import geoip2.database\n",
    "import myLogReader as mlr\n",
    "import pythonClassExample as pce\n",
    "import re\n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate - Read and Prep log data into DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListOfFiles(dirName):\n",
    "    # names in the given directory \n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "    \n",
    "    for file in listOfFile:\n",
    "        # Create full path\n",
    "        fullPath = os.path.join(dirName, file)\n",
    "        # If entry is a directory then get the list of files in this directory \n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "    return allFiles\n",
    "\n",
    "def readLog(file):\n",
    "    log_df = pd.read_csv(file\n",
    "            #,skiprows=[0,1,2,3]\n",
    "            , comment='#'\n",
    "            , sep=' ' \n",
    "            , usecols=[0,1, 2, 5, 6, 7, 8, 9, 10,11,12,14]\n",
    "            , na_values='-'\n",
    "            , names=['date'\n",
    "                    ,'time'\n",
    "                    ,'server-ip'\n",
    "                    ,'cs-uri-query'\n",
    "                    ,'server-port'\n",
    "                    ,'cs-username'\n",
    "                    ,'client-ip'\n",
    "                    ,'cs(User-Agent)'\n",
    "                    ,'cs(Referer)'\n",
    "                    ,'sc-status'\n",
    "                    ,'sc-substatus'\n",
    "                   ,'time-taken(ms)'])\n",
    "    return log_df\n",
    "\n",
    "def getDevice (UserAgentResponse):\n",
    "    device ='Other' \n",
    "    if 'Mobi' in UserAgentResponse:\n",
    "        device = 'Mobile'\n",
    "    else:\n",
    "        device = 'Desktop'\n",
    "    return device\n",
    "\n",
    "def getBrowser (UserAgentResponse):\n",
    "    browser ='Other' \n",
    "    if 'Firefox' in UserAgentResponse and 'Seamonkey' not in UserAgentResponse:\n",
    "        browser = 'Firefox'\n",
    "    elif 'Seamonkey' in UserAgentResponse:\n",
    "        browser = 'Seamonkey'\n",
    "    elif 'Chrome' in UserAgentResponse and 'Chromium' not in UserAgentResponse:\n",
    "        browser = 'Chrome'\n",
    "    elif ('Safari' in UserAgentResponse and 'Chromium' not in UserAgentResponse and 'Chrome' not in UserAgentResponse):\n",
    "        browser = 'Safari'\n",
    "    elif 'OPR' in UserAgentResponse and 'Opera'  in UserAgentResponse:\n",
    "        browser = 'Opera'\n",
    "    elif '; MSIE' in UserAgentResponse:\n",
    "        browser = 'IE'\n",
    "    return browser\n",
    "\n",
    "def GetWebPageSection(x):\n",
    "    section = 'Unknown'\n",
    "    r = re.compile('([A-Z])\\w+')\n",
    "    section = r.search(x)\n",
    "    if section is not None:\n",
    "        return section.group()\n",
    "    return section\n",
    "\n",
    "def deriveClientDevice(iis_log_df):\n",
    "    iis_log_df['client-device']  =  iis_log_df['cs(User-Agent)'].apply(lambda x: getDevice(str(x)))\n",
    "    return iis_log_df\n",
    "\n",
    "def deriveClientBrowser(iis_log_df):\n",
    "    iis_log_df['client-browser'] =  iis_log_df['cs(User-Agent)'].apply(lambda x: getBrowser(str(x)))\n",
    "    return iis_log_df\n",
    "\n",
    "def deriveClientWebPage(iis_log_df):\n",
    "    iis_log_df['client-webPage'] = iis_log_df['cs(Referer)'].apply(lambda x: GetWebPageSection(x) if type(x) != float else np.nan)\n",
    "    return iis_log_df\n",
    "\n",
    "def deriveClientCity(iis_log_df):\n",
    "    #print(iis_log_df)\n",
    "    iis_log_df['client-city'] =  iis_log_df['client-ip'].apply(lambda x: reader.city(ip_address=x).city.name if reader.city(ip_address=x).city.name != None else np.nan)\n",
    "    return iis_log_df\n",
    "    \n",
    "def deriveClientCountry(iis_log_df):    \n",
    "    iis_log_df['client-country'] =  iis_log_df['client-ip'].apply(lambda x: reader.city(ip_address=x).country.name if reader.city(ip_address=x).country.name != None else np.nan)\n",
    "    return iis_log_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function to loop through logs and load the data into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLogs(logsPath,geoLiteIPDBPath):\n",
    "    df = pd.DataFrame()\n",
    "    #instantiate log reader\n",
    "    reader = geoip2.database.Reader(geoLiteIPDBPath)\n",
    "    \n",
    "    listOfFiles = getListOfFiles(logsPath)\n",
    "    \n",
    "    try:    \n",
    "        for file in listOfFiles:\n",
    "            #print (file)\n",
    "            log_df =  readLog(file)\n",
    "            log_df = deriveClientCity(log_df)\n",
    "            log_df = deriveClientCountry(log_df)\n",
    "            log_df = deriveClientDevice(log_df)\n",
    "            log_df = deriveClientBrowser(log_df)\n",
    "            log_df = deriveClientWebPage(log_df)\n",
    "            log_df = deriveClientCity(log_df)\n",
    "            log_df = deriveClientCountry(log_df)\n",
    "            df = pd.concat([df,log_df])\n",
    "            os.rename(file,'../data/success/' + file[file.find('u'):])\n",
    "    except Exception:\n",
    "        os.rename(file,'../data/error/' + file[file.find('u'):])\n",
    "        print('Moving file '+ file + ' to ../data/error/')\n",
    "            \n",
    "    finally:        \n",
    "        reader.close()\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load all logs into DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logsPath = '../data/logs'\n",
    "geoLiteIPDBPath = '../data/GeoLite2-City_20181009/GeoLite2-City.mmdb'\n",
    "\n",
    "df =  readLogs(logsPath,geoLiteIPDBPath)\n",
    "\n",
    "\n",
    "'''df = deriveCityFromIP(df)\n",
    "\n",
    "df = deriveCountryFromIP(df)\n",
    "\n",
    "df = deriveClientDevice(df)\n",
    "df = deriveClientBrowser(df)\n",
    "df = deriveClientWebPage(df)\n",
    "\n",
    "df = deriveClientCity(df)\n",
    "df = deriveClientCountry(df)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2- Automate load logs and aggregate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_browser_df = (df.groupby(by=['date','client-browser'])['client-browser']\n",
    "                        .count()\n",
    "                        .reset_index(level=1,name='Count')\n",
    "                        .pivot(columns='client-browser',values='Count'))\n",
    "\n",
    "client_city_df = (df.groupby(by=['date','client-city'])['client-city']\n",
    "            .count()\n",
    "            .reset_index(level=1,name='Count')\n",
    "            .pivot(columns='client-city',values='Count'))\n",
    "\n",
    "client_country_df = (df.groupby(by=['date','client-country'])['client-country']\n",
    "            .count()\n",
    "            .reset_index(level=1,name='Count')\n",
    "            .pivot(columns='client-country',values='Count'))\n",
    "\n",
    "client_device_df = (df.groupby(by=['date','client-device'])['client-device']\n",
    "            .count()\n",
    "            .reset_index(level=1,name='Count')\n",
    "            .pivot(columns='client-device',values='Count'))\n",
    "\n",
    "client_webPage_df = (df.groupby(by=['date','client-webPage'])['client-webPage']\n",
    "            .count()\n",
    "            .reset_index(level=1,name='Count')\n",
    "            .pivot(columns='client-webPage',values='Count'))\n",
    "\n",
    "(df.groupby(by=['date','client-ip'])['client\n",
    "                                     -ip']\n",
    "            .count()\n",
    "            .reset_index(level=1,name='Count')\n",
    "            .pivot(columns='client-ip',values='Count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[10:20,[0,5,6,11,12,13,14,15,16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"server-port\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive Calendar Week, year after aggregating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date-weekday']   = df['date'].apply(lambda x: 'Weekday' if np.int8(str(dt.datetime.strptime(x,'%Y-%m-%d').weekday())) < 5 else 'Weekend')\n",
    "df['date-calendar-week']   = df['date'].apply(lambda x: np.int8(str(dt.datetime.strptime(x,'%Y-%m-%d').isocalendar()[1])))\n",
    "df['date-year']   = df['date'].apply(lambda x: dt.datetime.strptime(x,'%Y-%m-%d').year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, df.dtypes == object].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "d =dt.datetime.strptime(df.date.loc[1],'%Y-%m-%d')\n",
    "d =dt.datetime.strptime('2018-12-28','%Y-%m-%d')\n",
    "d.year\n",
    "#np.int8(str(d.year))\n",
    "\n",
    "#iis_logs_df.date.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
